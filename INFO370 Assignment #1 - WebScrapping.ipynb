{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Importing packages\n",
    "\n",
    "import re                                    \n",
    "import pandas as pd                          \n",
    "import urllib.request as urllib2                                \n",
    "from bs4 import BeautifulSoup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Getting data from website and using BeautifulSoup for easy navigation \n",
    "\n",
    "url=\"http://liberalarts.utexas.edu/english/faculty/\"            # First of many URLs to scrape\n",
    "firstPage = urllib2.urlopen(url)                                # Open page\n",
    "UTEnglishFac = BeautifulSoup(firstPage.read(), 'html.parser')   # Parse page using HTML parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Populating Names, PhD info, and job info for first webpage\n",
    "\n",
    "facultyInfos = UTEnglishFac.find_all(\"div\", { \"class\" : \"small-8 medium-9 large-10 columns faculty-contact-info\" })\n",
    "\n",
    "# Initialize empty lists\n",
    "fNames = [] \n",
    "lNames = []\n",
    "jobTitles = []\n",
    "ph_DSchools = []\n",
    "ph_DYears = []\n",
    "ph_DDept = []\n",
    "\n",
    "# Storing information in respective lists\n",
    "for facultyInfo in facultyInfos:\n",
    "    \n",
    "    potentialEducation = facultyInfo.find('span', attrs={'class' : 'education'})\n",
    "    \n",
    "    if potentialEducation is not None:\n",
    "        \n",
    "        anEducation = [e.strip() for e in potentialEducation.next_sibling.string.split(',') if e.strip() is not None]\n",
    "        \n",
    "        # Only concerned with individuals with Ph.D.s\n",
    "        if ((anEducation[0] == \"Ph.D.\")):\n",
    "\n",
    "            fullName = [n.strip() for n in re.split('\\s|\\.', facultyInfo.find(\"h3\").string) if n.strip()]         # Split on spaces or \".\" to account for middle initials\n",
    "\n",
    "            # Error handling and Cleaning\n",
    "            if ((len(fullName) == 3) and (len(fullName[1]) == 1)):\n",
    "                fNames.append(fullName[0])\n",
    "                lNames.append(fullName[2])\n",
    "            elif((len(fullName) == 3) and (len(fullName[1]) > 1)):\n",
    "                fNames.append(fullName[0])\n",
    "                lNames.append(fullName[1] + \" \" + fullName[2])\n",
    "            else:\n",
    "                fNames.append(fullName[0])\n",
    "                lNames.append(fullName[1])\n",
    "        \n",
    "            jobTitle = facultyInfo.find(\"h6\").string    \n",
    "            jobTitles.append(jobTitle)\n",
    "            \n",
    "            # Error handling and Cleaning\n",
    "            if (len(anEducation) > 5):\n",
    "                ph_DDept.append(anEducation[2])\n",
    "                ph_DYears.append(anEducation[1])\n",
    "                ph_DSchools.append(anEducation[3])\n",
    "            \n",
    "            if (len(anEducation) == 5):\n",
    "                ph_DDept.append(anEducation[1])\n",
    "                ph_DYears.append(anEducation[2])\n",
    "                ph_DSchools.append(anEducation[3] + \" at \" + anEducation[4])\n",
    "            \n",
    "            if (len(anEducation) == 4):\n",
    "                if ((fullName[0] == \"Helena\") and (fullName[1] == \"Woodard\")):\n",
    "                    ph_DDept.append(anEducation[2])\n",
    "                    ph_DYears.append(anEducation[1])\n",
    "                    ph_DSchools.append(anEducation[3])\n",
    "                \n",
    "                elif ((anEducation[3] == \"Berkeley\") or (anEducation[3] == \"San Diego\")):\n",
    "                    ph_DDept.append(\"Unspecified\")\n",
    "                    ph_DYears.append(anEducation[1])\n",
    "                    ph_DSchools.append(anEducation[2] + \" at \" + anEducation[3])\n",
    "                \n",
    "                else:\n",
    "                    ph_DDept.append(anEducation[1])\n",
    "                    ph_DYears.append(anEducation[2])\n",
    "                    ph_DSchools.append(anEducation[3])\n",
    "            \n",
    "            if (len(anEducation) == 3):\n",
    "                ph_DDept.append(\"Unspecified\")\n",
    "                ph_DYears.append(anEducation[1])\n",
    "                ph_DSchools.append(anEducation[2])\n",
    "            \n",
    "            if (len(anEducation) == 2):\n",
    "                ph_DDept.append(\"Unspecified\")\n",
    "                ph_DYears.append(\"Unspecified\")\n",
    "                ph_DSchools.append(anEducation[1])\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "secondUrl=\"http://liberalarts.utexas.edu/economics/faculty/\"    # Second of many URLs to scrape\n",
    "secondPage = urllib2.urlopen(secondUrl)                         # Open page\n",
    "UTEconFac = BeautifulSoup(secondPage.read(), 'html.parser')     # Parse page using HTML parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Populating Names, PhD info, and job info for second webpage\n",
    "\n",
    "moreFacultyInfos = UTEconFac.find_all(\"div\", { \"class\" : \"small-8 medium-9 large-10 columns faculty-contact-info\" })\n",
    "\n",
    "# Appending new information to already-created lists \n",
    "for anotherFacultyInfo in moreFacultyInfos:\n",
    "    \n",
    "    anotherPotentialEducation = anotherFacultyInfo.find('span', attrs={'class' : 'education'})\n",
    "    \n",
    "    if anotherPotentialEducation is not None:\n",
    "        \n",
    "        anotherEducation = [e2.strip() for e2 in anotherPotentialEducation.next_sibling.string.split(',') if e2.strip() is not None]\n",
    "        \n",
    "        if ((anotherEducation[0] == \"Ph.D.\")):\n",
    "            \n",
    "            fullNameEcon = [n.strip() for n in re.split('\\s|\\.', anotherFacultyInfo.find(\"h3\").string) if n.strip()]               # Split on spaces or \".\" to account for middle initials\n",
    "            \n",
    "            # Error handling and Cleaning\n",
    "            if ((len(fullNameEcon) == 3) and (len(fullNameEcon[1]) == 1)):\n",
    "                fNames.append(fullNameEcon[0])\n",
    "                lNames.append(fullNameEcon[2])\n",
    "            elif((len(fullNameEcon) == 3) and (len(fullNameEcon[1]) > 1)):\n",
    "                fNames.append(fullNameEcon[0])\n",
    "                lNames.append(fullNameEcon[1] + \" \" + fullNameEcon[2])\n",
    "            elif((len(fullNameEcon) == 2) and (fullNameEcon[1] == \"Bhaskar\")):\n",
    "                fNames.append(fullNameEcon[0] + \".\")\n",
    "                lNames.append(fullNameEcon[1])\n",
    "            else:\n",
    "                fNames.append(fullNameEcon[0])\n",
    "                lNames.append(fullNameEcon[1])\n",
    "            \n",
    "            jobTitleEcon = anotherFacultyInfo.find(\"h6\").string    \n",
    "            jobTitles.append(jobTitleEcon)\n",
    "            \n",
    "            # Error handling and Cleaning\n",
    "            if (len(anotherEducation) == 3):\n",
    "                ph_DDept.append(\"Unspecified\")\n",
    "                ph_DYears.append(\"Unspecified\")\n",
    "                ph_DSchools.append(anotherEducation[1] + \" at \" + anotherEducation[2])\n",
    "            \n",
    "            if (len(anotherEducation) == 2):\n",
    "                ph_DDept.append(\"Unspecified\")\n",
    "                ph_DYears.append(\"Unspecified\")\n",
    "                ph_DSchools.append(anotherEducation[1])\n",
    "\n",
    "# Initializing lists with known, predictable values\n",
    "currentSchool = ([\"University of Texas at Austin\"] * 134)\n",
    "currentSchoolID = ([\"49\"] * 134)\n",
    "currentDepts = (([\"English\"] * 94) + ([\"Economics\"] * 40))\n",
    "startYear = ([\"Unspecified\"] * 134)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Map University names to IDs\n",
    "\n",
    "# Will be required to have this csv downloaded before code can be run. Clone from my github repo named: \"WebScraping\"\n",
    "schoolCodesFromDoc = pd.read_csv(\"~/Downloads/WebScraping/school_codes.csv\")\n",
    "\n",
    "schoolIDs = schoolCodesFromDoc[\"id\"].tolist()\n",
    "\n",
    "schoolNames = schoolCodesFromDoc[\"name\"].tolist()\n",
    "\n",
    "# Make Dictionary with keys as names and IDs as values from Google Sheets\n",
    "schoolIDsToNames = dict(zip(schoolNames, schoolIDs))\n",
    "\n",
    "# Intialize empty array for storing IDs\n",
    "ph_DSchoolIDs = []\n",
    "\n",
    "# If not in dictionary, add to dictionary\n",
    "for ph_DSchool in ph_DSchools:\n",
    "    if ph_DSchool in schoolIDsToNames:\n",
    "        ph_DSchoolIDs.append(schoolIDsToNames.get(ph_DSchool))\n",
    "    else:\n",
    "        schoolIDsToNames[ph_DSchool] = (len(schoolIDsToNames) + 1)\n",
    "        ph_DSchoolIDs.append(len(schoolIDsToNames))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create DataFrame and insert lists as columns\n",
    "\n",
    "tabulatedInfo = pd.DataFrame({'First Name': fNames, 'Last Name': lNames, 'University of Ph.D.': ph_DSchools, 'University of Ph.D. ID': ph_DSchoolIDs, 'Department of Ph.D.': ph_DDept, 'Year of Ph.D.': ph_DYears, 'School of Faculty Position': currentSchool, 'Current School ID': currentSchoolID, 'Department of Faculty Position': currentDepts, 'Year Faculty Started': startYear, 'Job Title': jobTitles})\n",
    "\n",
    "# Set Index to be at 1\n",
    "tabulatedInfo.index += 1\n",
    "\n",
    "# Reorder columns to adhere to required format\n",
    "tabulatedInfo = tabulatedInfo[['First Name', 'Last Name', 'University of Ph.D.', 'University of Ph.D. ID', 'Department of Ph.D.', 'Year of Ph.D.', 'School of Faculty Position', 'Current School ID', 'Department of Faculty Position', 'Year Faculty Started', 'Job Title']]                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write table to csv file.\n",
    "\n",
    "tabulatedInfo.to_csv(\"ArvindKrishWebScrappingOutput.csv\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
